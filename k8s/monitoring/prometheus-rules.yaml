apiVersion: v1
kind: ConfigMap
metadata:
  name: prometheus-rules
  namespace: monitoring
  labels:
    app: prometheus
data:
  alert-rules.yml: |
    groups:
      - name: smart-incident-bot-alerts
        rules:
          # High Error Rate Alert
          - alert: HighErrorRate
            expr: |
              sum(rate(http_server_requests_seconds_count{status=~"5..", job="smart-incident-bot"}[5m])) 
              / 
              sum(rate(http_server_requests_seconds_count{job="smart-incident-bot"}[5m])) 
              * 100 > 5
            for: 2m
            labels:
              severity: critical
              service: smart-incident-bot
            annotations:
              summary: "High error rate detected"
              description: "Error rate is {{ $value | printf \"%.2f\" }}% (threshold: 5%)"

          # High Latency Alert
          - alert: HighLatency
            expr: |
              histogram_quantile(0.99, 
                sum(rate(http_server_requests_seconds_bucket{job="smart-incident-bot"}[5m])) by (le)
              ) > 2
            for: 2m
            labels:
              severity: warning
              service: smart-incident-bot
            annotations:
              summary: "High latency detected"
              description: "P99 latency is {{ $value | printf \"%.2f\" }}s (threshold: 2s)"

          # High CPU Usage
          - alert: HighCPU
            expr: |
              sum(rate(process_cpu_seconds_total{job="smart-incident-bot"}[5m])) * 100 > 90
            for: 5m
            labels:
              severity: warning
              service: smart-incident-bot
            annotations:
              summary: "High CPU usage detected"
              description: "CPU usage is {{ $value | printf \"%.2f\" }}%"

          # High Memory Usage
          - alert: HighMemory
            expr: |
              (jvm_memory_used_bytes{area="heap", job="smart-incident-bot"} 
              / 
              jvm_memory_max_bytes{area="heap", job="smart-incident-bot"}) * 100 > 85
            for: 5m
            labels:
              severity: warning
              service: smart-incident-bot
            annotations:
              summary: "High JVM heap memory usage"
              description: "Heap memory usage is {{ $value | printf \"%.2f\" }}%"

          # Pod Restarts
          - alert: PodRestarts
            expr: |
              increase(kube_pod_container_status_restarts_total{pod=~"smart-incident-bot.*"}[10m]) > 3
            for: 1m
            labels:
              severity: critical
              service: smart-incident-bot
            annotations:
              summary: "Pod experiencing frequent restarts"
              description: "Pod has restarted {{ $value }} times in the last 10 minutes"

          # Target Down
          - alert: TargetDown
            expr: up{job="smart-incident-bot"} == 0
            for: 1m
            labels:
              severity: critical
              service: smart-incident-bot
            annotations:
              summary: "Smart Incident Bot is down"
              description: "The application is not responding to health checks"

          # Incident Created
          - alert: IncidentCreated
            expr: increase(incidents_created_total{job="smart-incident-bot"}[5m]) > 0
            for: 0m
            labels:
              severity: info
              service: smart-incident-bot
            annotations:
              summary: "New incident created"
              description: "{{ $value }} new incident(s) created in the last 5 minutes"
